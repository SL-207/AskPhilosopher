{"paragraph": " The individual now constitutes the entire system, but it doesn’t seem that memorization of the rulebook would be sufficient for them to understand Mandarin. Another common response (also directed against premise 1), often called the Robot Reply, contends that the lack of understanding results from the fact that the system lacks any sensory organs and cannot interact with the world (see Fodor 1980, Harnad 1991). These de- ficiencies prevent it from being able to connect the symbols that it is manipulating to the objects and states of affair that those symbols are meant to represent. To try to rebut this objection, Searle suggests another modification to the original thought experiment. Suppose we put the entire room inside the head of a giant robot. This robot has cameras and other sensors that take input from the world, and now some of the characters that are slipped into the room come via the cameras and sensors. According to Searle, the fact that these sym- bols are coming from a different source doesn’t have any effect on your understanding. You are still just doing what you have always been ­doing—namely, manipulating symbols without understanding what they symbolize. Searle also suggests that, in granting that something like sensory perception is needed for understanding, the Robot Reply tacitly concedes his conclusion: no computer can come to achieve understanding merely in virtue of running a symbolic program con- sisting of syntactically specified rules. A different kind of response targets the structure of Searle’s example. Paul and Patricia Churchland (1990) propose a parallel ­argument— what they call the Luminous Room. You inside the room are given a magnet, and told to wave it as fast as you can. No matter how much you wave it, however, you don’t produce any visible light. It thus looks like we could conclude that electromagnetic forces are not sufficient to produce light.", "metadata": "Philosophy of Mind_ 50 Puzzles, Paradoxes, and Thought Experiments by Torin Alter & Robert J", "question": "What is the implication of the Luminous Room argument for the idea that a computer can come to understand language through a symbolic program?", "answer": "The Luminous Room argument implies that a symbolic program is not sufficient for a computer to understand language. This is because the program may not necessarily correspond to the real-world objects or states of affairs that the symbols are meant to represent.", "question_group_id": "45d5e323-5cb6-4ae4-9195-0212b9254e45", "paragraph_idx": 210, "question_idx": 3}