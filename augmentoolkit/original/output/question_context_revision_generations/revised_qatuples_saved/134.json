{"paragraph": " 2. The person in the Chinese Room doesn’t understand Mandarin. 3. Thus, strong AI is false. The Chinese Room example also seems to pose a problem to ­functionalism—a theory of mind that treats mental states as functional states. While we have already seen other problems for functionalism that arise from its inability to handle the phenomenal character of our mental states (see Chapters 15 and 16), this example suggests that functionalism cannot adequately handle the intentional content of our mental states—that is, the aspect of our mental states in virtue of which they are about or directed at objects or states of affairs. One slogan commonly associated with functionalism is that the mind is to the brain as a computer software is to its hardware. In the Chinese Room, however, you are running the right software for understanding Mandarin, but yet you are not in the state of understanding Mandarin. Though Mandarin speakers use these characters to refer to objects or states of affair, to you they are every bit as meaningless after you’ve mastered the rulebook as when you first entered the room. Thus, if this example succeeds, it seems that functionalism must be false. DISCUSSION One common response to the Chinese Room is to argue that Searle was looking for understanding in the wrong place. When strong AI claims that computers can achieve understanding, they attribute the understanding to the entire computing system. But the person inside the room is only one part of the system—there is also the rulebook. Though you may not understand Mandarin as a result of being in the Chinese Room, that does not mean that the whole system lacks such understanding (see Copeland 1993). In terms of the argument out- lined above, premise 1 is rejected. To try to rebut this objection, which The Chinese Room 107 Searle refers to as the Systems Reply, he suggests that the individual in the room could memorize the entire rulebook.", "metadata": "Philosophy of Mind_ 50 Puzzles, Paradoxes, and Thought Experiments by Torin Alter & Robert J", "question": "Does the Chinese Room example provide evidence that strong AI is false?", "answer": "Yes, the Chinese Room example suggests that strong AI is false. The person in the room follows the rules to generate Chinese characters, but they do not understand the language. This contradicts the idea that strong AI holds, which is that a computer can understand and think like a human being.", "question_group_id": "81931bb4-3620-45bf-b9a3-9cad10bed4d2", "paragraph_idx": 204, "question_idx": 0}